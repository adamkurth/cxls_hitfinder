{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pkg import c, m, f \n",
    "import torch\n",
    "import logging\n",
    "from pkg import c, m, f \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of peak images: 947\n",
      "Number of water images: 947\n",
      "Number of label images: 947\n",
      "<class 'numpy.ndarray'>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "cfg = {\n",
    "    'batch_size': 100,\n",
    "    'threshold_value': 10,\n",
    "    'num_epochs': 10,\n",
    "    'learning_rate': 0.001,\n",
    "    'classes': 2\n",
    "}\n",
    "\n",
    "# classes \n",
    "paths = c.PathManager()\n",
    "data = c.PeakImageDataset(paths)\n",
    "prep = c.DataPreparation(paths, data, batch_size=cfg['batch_size'])\n",
    "water_h5 = data.load_h5(paths.water_background_h5)\n",
    "ip = c.ImageProcessor(water_h5)\n",
    "p = c.PeakThresholdProcessor(threshold_value=cfg['threshold_value'])\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.is_available())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BasicCNN1', 'BasicCNN2', 'DenseNet121_Weights', 'DenseNetBraggPeakClassifier', 'F', 'ResNet50BraggPeakClassifier', 'ResNet50_Weights', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'models', 'nn', 'np', 'optim', 'os', 'torch']\n"
     ]
    }
   ],
   "source": [
    "# if not already generated \n",
    "# ip.process_directory(paths, p.threshold_value) \n",
    "print(dir(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criterion:  BCEWithLogitsLoss()\n",
      "Optimizer:  Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Learning rate:  0.001\n",
      "Data prepared.\n",
      "Train size: 757\n",
      "Test size: 190\n",
      "Batch size: 100\n",
      "Number of batches in train_loader: 8 \n",
      "\n",
      "\n",
      "Model: BasicCNN1\n",
      "Training and testing the model...\n",
      "-- epoch 0\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 26.68 GiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 58.69 GiB is allocated by PyTorch, and 25.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m batch \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(loader[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mlen\u001b[39m(loader[\u001b[38;5;241m1\u001b[39m])]\n\u001b[0;32m     24\u001b[0m classes \u001b[38;5;241m=\u001b[39m cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclasses\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 26\u001b[0m f\u001b[38;5;241m.\u001b[39mtrain_test_model(model, loader, criterion, optimizer, epochs, device, N, batch, classes)\n\u001b[0;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39mcpu()  \u001b[38;5;66;03m# Move model back to CPU to free up GPU memory\u001b[39;00m\n\u001b[0;32m     29\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[1;32mc:\\Users\\eseveret\\Desktop\\cxls_hitfinder\\cnn\\src\\pkg\\functions.py:165\u001b[0m, in \u001b[0;36mtrain_test_model\u001b[1;34m(model, loader, criterion, optimizer, epochs, device, N, batch, classes)\u001b[0m\n\u001b[0;32m    162\u001b[0m score \u001b[38;5;241m=\u001b[39m model(peak_images)\n\u001b[0;32m    163\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(score, labels)\n\u001b[1;32m--> 165\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    166\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    167\u001b[0m running_loss_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# Convert to Python number with .item()\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eseveret\\AppData\\Local\\anaconda3\\envs\\hitfinder_env\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    524\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\eseveret\\AppData\\Local\\anaconda3\\envs\\hitfinder_env\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    267\u001b[0m     tensors,\n\u001b[0;32m    268\u001b[0m     grad_tensors_,\n\u001b[0;32m    269\u001b[0m     retain_graph,\n\u001b[0;32m    270\u001b[0m     create_graph,\n\u001b[0;32m    271\u001b[0m     inputs,\n\u001b[0;32m    272\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    273\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m )\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 26.68 GiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 58.69 GiB is allocated by PyTorch, and 25.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    m.BasicCNN1(),\n",
    "    m.BasicCNN2(),\n",
    "    m.ResNet50BraggPeakClassifier(),\n",
    "    m.DenseNetBraggPeakClassifier()\n",
    "]\n",
    "\n",
    "for i in models:\n",
    "    model = i.to(device)\n",
    "    # loss function/ combines a Sigmoid layer and the BCELoss in one single class\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=cfg['learning_rate'])\n",
    "    print(\"Criterion: \", criterion)\n",
    "    print(\"Optimizer: \", optimizer)\n",
    "    print(\"Learning rate: \", optimizer.param_groups[0]['lr'])\n",
    "    # data loaders \n",
    "    train_loader, test_loader = prep.prep_data()\n",
    "    loader = [train_loader, test_loader]\n",
    "    N = [len(loader[0].dataset), len(loader[1].dataset)]\n",
    "\n",
    "    epochs = cfg['num_epochs']\n",
    "    batch = [len(loader[0]), len(loader[1])]\n",
    "    classes = cfg['classes']\n",
    "\n",
    "    f.train_test_model(model, loader, criterion, optimizer, epochs, device, N, batch, classes)\n",
    "    \n",
    "    model.cpu()  # Move model back to CPU to free up GPU memory\n",
    "    torch.cuda.empty_cache()  # Clear unused memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
