{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pkg import c, m, f \n",
    "import torch\n",
    "import logging\n",
    "from pkg import c, m, f \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of peak images: 20\n",
      "Number of water images: 20\n",
      "Number of label images: 20\n",
      "<class 'numpy.ndarray'>\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "cfg = {\n",
    "    'batch_size': 1,\n",
    "    'threshold_value': 10,\n",
    "    'num_epochs': 2,\n",
    "    'learning_rate': 0.001,\n",
    "    'classes': 2\n",
    "}\n",
    "\n",
    "# classes \n",
    "paths = c.PathManager()\n",
    "data = c.PeakImageDataset(paths)\n",
    "prep = c.DataPreparation(paths, data, batch_size=cfg['batch_size'])\n",
    "water_h5 = data.load_h5(paths.water_background_h5)\n",
    "ip = c.ImageProcessor(water_h5)\n",
    "p = c.PeakThresholdProcessor(threshold_value=cfg['threshold_value'])\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.is_available())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BasicCNN1', 'BasicCNN2', 'DenseNet121_Weights', 'DenseNetBraggPeakClassifier', 'F', 'ResNet50BraggPeakClassifier', 'ResNet50_Weights', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'models', 'nn', 'np', 'optim', 'os', 'torch']\n"
     ]
    }
   ],
   "source": [
    "# if not already generated \n",
    "# ip.process_directory(paths, p.threshold_value) \n",
    "print(dir(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criterion:  BCEWithLogitsLoss()\n",
      "Optimizer: \n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Learning rate:  0.001\n",
      "Data prepared.\n",
      "Train size: 16\n",
      "Test size: 4\n",
      "Batch size: 1\n",
      "Number of batches in train_loader: 16 \n",
      "\n",
      "\n",
      "Model: BasicCNN1\n",
      "Training and testing the model...\n",
      "-- epoch 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m batch \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(loader[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mlen\u001b[39m(loader[\u001b[38;5;241m1\u001b[39m])]\n\u001b[1;32m     24\u001b[0m classes \u001b[38;5;241m=\u001b[39m cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclasses\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 26\u001b[0m f\u001b[38;5;241m.\u001b[39mtrain_test_model(model, loader, criterion, optimizer, epochs, device, N, batch, classes)\n",
      "File \u001b[0;32m~/Desktop/CXFEL/cxls_hitfinder/cnn/src/pkg/functions.py:167\u001b[0m, in \u001b[0;36mtrain_test_model\u001b[0;34m(model, loader, criterion, optimizer, epochs, device, N, batch, classes)\u001b[0m\n\u001b[1;32m    164\u001b[0m score \u001b[38;5;241m=\u001b[39m model(peak_images)\n\u001b[1;32m    165\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(score, labels)\n\u001b[0;32m--> 167\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    168\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    169\u001b[0m running_loss_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# Convert to Python number with .item()\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    m.BasicCNN1(),\n",
    "    m.BasicCNN2(),\n",
    "    m.ResNet50BraggPeakClassifier(),\n",
    "    m.DenseNetBraggPeakClassifier()\n",
    "]\n",
    "\n",
    "for i in models:\n",
    "    model = i.to(device)\n",
    "    # loss function/ combines a Sigmoid layer and the BCELoss in one single class\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=cfg['learning_rate'])\n",
    "    print(\"Criterion: \", criterion)\n",
    "    print(\"Optimizer: \\n\", optimizer)\n",
    "    print(\"Learning rate: \", optimizer.param_groups[0]['lr'])\n",
    "    # data loaders \n",
    "    train_loader, test_loader = prep.prep_data()\n",
    "    loader = [train_loader, test_loader]\n",
    "    N = [len(loader[0].dataset), len(loader[1].dataset)]\n",
    "\n",
    "    epochs = cfg['num_epochs']\n",
    "    batch = [len(loader[0]), len(loader[1])]\n",
    "    classes = cfg['classes']\n",
    "\n",
    "    f.train_test_model(model, loader, criterion, optimizer, epochs, device, N, batch, classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
