{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/adamkurth/Documents/vscode/CXFEL/cxls_hitfinder/images/water/01/water01.h5', '/Users/adamkurth/Documents/vscode/CXFEL/cxls_hitfinder/images/water/02/water02.h5', '/Users/adamkurth/Documents/vscode/CXFEL/cxls_hitfinder/images/water/03/water03.h5']\n",
      "['/Users/adamkurth/Documents/vscode/CXFEL/cxls_hitfinder/images/water/01/water01.h5', '/Users/adamkurth/Documents/vscode/CXFEL/cxls_hitfinder/images/water/02/water02.h5', '/Users/adamkurth/Documents/vscode/CXFEL/cxls_hitfinder/images/water/03/water03.h5']\n",
      "/Users/adamkurth/Documents/vscode/CXFEL/cxls_hitfinder/images/water/01/water01.h5\n",
      "{'01': '/Users/adamkurth/Documents/vscode/CXFEL/cxls_hitfinder/images/water/01/water01.h5', '02': '/Users/adamkurth/Documents/vscode/CXFEL/cxls_hitfinder/images/water/02/water02.h5', '03': '/Users/adamkurth/Documents/vscode/CXFEL/cxls_hitfinder/images/water/03/water03.h5'}\n"
     ]
    }
   ],
   "source": [
    "from pkg import *\n",
    "paths = path.PathManager(datasets=[1,2,3])\n",
    "# print(paths.total_paths.peaks)\n",
    "# print(paths.total_paths.water_background)\n",
    "\n",
    "processor = process.Processor(paths=paths, datasets=[1,2,3])\n",
    "# print(processor.water_backgrounds)\n",
    "\n",
    "# focus on water_background dict\n",
    "datasets_int = f.convert2int(processor.datasets)\n",
    "# print(processor.datasets)\n",
    "# print(datasets_int)\n",
    "\n",
    "# returns dictionary of selected water_background paths\n",
    "print(processor.water_background_dict['01'])\n",
    "print(processor.water_background_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changes to `path.py`\n",
    "- `path.py` now takes in a list of ints, where each int corresponds to a dataset index. Inside of `path.select_datasets()`, this iterates through the list of ints and appends all paths to the corresponding datasets to the `datasets` list. This allows for the selection of multiple datasets at once.\n",
    "- The instance of PathManager, `myPaths`, now has the attribute of `total_paths` where this is a namedtuple that contains all the paths to the dataset(s).\n",
    "\n",
    "- This change makes it easier to select multiple datasets at once, and allows for the selection of datasets in a more flexible manner.\n",
    "\n",
    "\n",
    "- `init_list()` function takes the string `dataset` argument that pads the integer and has been casted to a string, then uses the `get_()` functions for all the files in the directories we need, returns many lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n",
      "['01', '02']\n"
     ]
    }
   ],
   "source": [
    "ints = f.convert2int(datasets=['01','02'])\n",
    "print(ints)\n",
    "strs = f.convert2str(datasets=[1,2])\n",
    "print(strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'01': {'clen': 0.15, 'photon_energy': 6000}, '02': {'clen': 0.15, 'photon_energy': 7000}, '03': {'clen': 0.15, 'photon_energy': 8000}}\n",
      "Paths refreshed for dataset ['01', '02', '03'].\n",
      "Directory: peaks/01\n",
      "\tTotal files: 75\n",
      "\tNormal images: 39\n",
      "\tEmpty images: 36\n",
      "Directory: labels/01\n",
      "\tTotal files: 75\n",
      "\tNormal images: 39\n",
      "\tEmpty images: 36\n",
      "Directory: peaks_water_overlay/01\n",
      "\tTotal files: 75\n",
      "\tNormal images: 39\n",
      "\tEmpty images: 36\n",
      "Directory: peaks/02\n",
      "\tTotal files: 17\n",
      "\tNormal images: 17\n",
      "\tEmpty images: 0\n",
      "Directory: labels/02\n",
      "\tTotal files: 17\n",
      "\tNormal images: 17\n",
      "\tEmpty images: 0\n",
      "Directory: peaks_water_overlay/02\n",
      "\tTotal files: 17\n",
      "\tNormal images: 17\n",
      "\tEmpty images: 0\n",
      "Directory: peaks/03\n",
      "\tTotal files: 15\n",
      "\tNormal images: 15\n",
      "\tEmpty images: 0\n",
      "Directory: labels/03\n",
      "\tTotal files: 15\n",
      "\tNormal images: 15\n",
      "\tEmpty images: 0\n",
      "Directory: peaks_water_overlay/03\n",
      "\tTotal files: 15\n",
      "\tNormal images: 15\n",
      "\tEmpty images: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from glob import glob\n",
    "from pkg import *\n",
    "\n",
    "datasets = [1,2,3]\n",
    "\n",
    "myPaths = path.PathManager(datasets=datasets)\n",
    "myProcessor = process.Processor(paths=myPaths, datasets=datasets)\n",
    "params = myProcessor.get_parameters()\n",
    "print(params)\n",
    "# print(f\"clen: {params.clen}, photon_energy: {params.photon_energy}\")\n",
    "\n",
    "f.get_counts(paths=myPaths, datasets=datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths refreshed for dataset ['01', '02', '03'].\n",
      "Directory: peaks/01\n",
      "\tTotal files: 75\n",
      "\tNormal images: 39\n",
      "\tEmpty images: 36\n",
      "Directory: labels/01\n",
      "\tTotal files: 75\n",
      "\tNormal images: 39\n",
      "\tEmpty images: 36\n",
      "Directory: peaks_water_overlay/01\n",
      "\tTotal files: 75\n",
      "\tNormal images: 39\n",
      "\tEmpty images: 36\n",
      "Directory: peaks/02\n",
      "\tTotal files: 17\n",
      "\tNormal images: 17\n",
      "\tEmpty images: 0\n",
      "Directory: labels/02\n",
      "\tTotal files: 17\n",
      "\tNormal images: 17\n",
      "\tEmpty images: 0\n",
      "Directory: peaks_water_overlay/02\n",
      "\tTotal files: 17\n",
      "\tNormal images: 17\n",
      "\tEmpty images: 0\n",
      "Directory: peaks/03\n",
      "\tTotal files: 15\n",
      "\tNormal images: 15\n",
      "\tEmpty images: 0\n",
      "Directory: labels/03\n",
      "\tTotal files: 15\n",
      "\tNormal images: 15\n",
      "\tEmpty images: 0\n",
      "Directory: peaks_water_overlay/03\n",
      "\tTotal files: 15\n",
      "\tNormal images: 15\n",
      "\tEmpty images: 0\n",
      "Directories '01' through '09' already created in '../../images/labels'.\n",
      "Directories '01' through '09' already created in '../../images/peaks'.\n",
      "Directories '01' through '09' already created in '../../images/peaks_water_overlay'.\n",
      "Directories '01' through '09' already created in '../../images/water'.\n",
      "Directories for dataset 01 have been processed. Matching file counts found.\n",
      "Directories for dataset 02 have been processed. Matching file counts found.\n",
      "Directories for dataset 03 have been processed. Matching file counts found.\n",
      "Directories for dataset 04 have been processed. Matching file counts found.\n",
      "Directories for dataset 05 have been processed. Matching file counts found.\n",
      "Directories for dataset 06 have been processed. Matching file counts found.\n",
      "Directories for dataset 07 are ready for processing (Step 1).\n",
      "Directories for dataset 08 are ready for processing (Step 1).\n",
      "Directories for dataset 09 are ready for processing (Step 1).\n",
      "Directory structure and image count verification completed successfully. Proceeding with data processing.\n",
      "\n",
      "Proceeding with data processing...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'images_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/vscode/CXFEL/cxls_hitfinder/cnn/src/process_directory.py:149\u001b[0m\n\u001b[1;32m    146\u001b[0m parser\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--percent_empty\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, help\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPercentage of empty images to add.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    147\u001b[0m args \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_args()\n\u001b[0;32m--> 149\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimages_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforce\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpercent_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpercent_empty\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/vscode/CXFEL/cxls_hitfinder/cnn/src/process_directory.py:134\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(images_dir, force, percent_empty)\u001b[0m\n\u001b[1;32m    132\u001b[0m     datasets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter dataset numbers (separated by commas): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    133\u001b[0m     datasets \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m(d))\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m datasets]\n\u001b[0;32m--> 134\u001b[0m     paths \u001b[38;5;241m=\u001b[39m \u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPathManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m     process_data(paths\u001b[38;5;241m=\u001b[39mpaths,image_directory\u001b[38;5;241m=\u001b[39mimages_dir, percent_empty\u001b[38;5;241m=\u001b[39mpercent_empty)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_valid \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m proceed_with_processing:\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'images_dir'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths refreshed for dataset ['01', '02', '03'].\n",
      "Directory: peaks/01\n",
      "\tTotal files: 75\n",
      "\tNormal images: 39\n",
      "\tEmpty images: 36\n",
      "Directory: labels/01\n",
      "\tTotal files: 75\n",
      "\tNormal images: 39\n",
      "\tEmpty images: 36\n",
      "Directory: peaks_water_overlay/01\n",
      "\tTotal files: 75\n",
      "\tNormal images: 39\n",
      "\tEmpty images: 36\n",
      "Directory: peaks/02\n",
      "\tTotal files: 17\n",
      "\tNormal images: 17\n",
      "\tEmpty images: 0\n",
      "Directory: labels/02\n",
      "\tTotal files: 17\n",
      "\tNormal images: 17\n",
      "\tEmpty images: 0\n",
      "Directory: peaks_water_overlay/02\n",
      "\tTotal files: 17\n",
      "\tNormal images: 17\n",
      "\tEmpty images: 0\n",
      "Directory: peaks/03\n",
      "\tTotal files: 15\n",
      "\tNormal images: 15\n",
      "\tEmpty images: 0\n",
      "Directory: labels/03\n",
      "\tTotal files: 15\n",
      "\tNormal images: 15\n",
      "\tEmpty images: 0\n",
      "Directory: peaks_water_overlay/03\n",
      "\tTotal files: 15\n",
      "\tNormal images: 15\n",
      "\tEmpty images: 0\n"
     ]
    }
   ],
   "source": [
    "f.get_counts(paths=myPaths, datasets=datasets)\n",
    "%run process_directory.py ../../images  --percent_empty 0.5 \n",
    "f.get_counts(paths=myPaths, datasets=datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths refreshed for dataset 01.\n",
      "Directory: peaks/01\n",
      "\tTotal files: 75\n",
      "\tNormal images: 39\n",
      "\tEmpty images: 36\n",
      "Directory: labels/01\n",
      "\tTotal files: 75\n",
      "\tNormal images: 39\n",
      "\tEmpty images: 36\n",
      "Directory: peaks_water_overlay/01\n",
      "\tTotal files: 75\n",
      "\tNormal images: 39\n",
      "\tEmpty images: 36\n",
      "Paths refreshed for dataset 01.\n",
      "Actual percentage of empty images: 48.0% across peaks, water_overlays, and labels directories.\n",
      "\n",
      "All files in dataset 01 of type 'peak' have matching attributes.\n",
      "All files in dataset 01 of type 'label' have matching attributes.\n",
      "All files in dataset 01 of type 'overlay' have matching attributes.\n",
      "All files in dataset 01 of type 'background' have matching attributes.\n",
      "Dataset 01 authenticated.\n",
      "\n",
      "Final dataset sizes - Peaks: 75, Labels: 75, Overlays: 75\n",
      "All files in dataset 01 of type 'peak' have matching attributes.\n",
      "All files in dataset 01 of type 'overlay' have matching attributes.\n",
      "All files in dataset 01 of type 'label' have matching attributes.\n",
      "\n",
      "Data prepared.\n",
      "Train size: 60\n",
      "Test size: 15\n",
      "Batch size: 10\n",
      "Number of batches in train_loader: 6 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDataManager = data.DatasetManager(paths=myPaths, dataset=dataset, parameters=[clen,photon_energy], transform=None)\n",
    "\n",
    "# peak, label, overlay are valid types\n",
    "clen, photon_energy = myProcessor.get_parameters()\n",
    "\n",
    "f.check_attributes(paths=myPaths, dataset=dataset, type='peak', clen=clen, photon_energy=photon_energy) \n",
    "f.check_attributes(paths=myPaths, dataset=dataset, type='overlay', clen=clen, photon_energy=photon_energy)\n",
    "f.check_attributes(paths=myPaths, dataset=dataset, type='label', clen=clen, photon_energy=photon_energy)\n",
    "\n",
    "train_loader, test_loader = f.prepare(data_manager=myDataManager, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files in dataset 01 of type 'peak' have matching attributes.\n",
      "{'clen': 1.5, 'peak': False, 'photon_energy': 6000}\n"
     ]
    }
   ],
   "source": [
    "f.check_attributes(paths=myPaths, dataset=dataset, type='peak', clen=clen, photon_energy=photon_energy)\n",
    "test_path = myPaths.get_peak_image_paths(dataset)[0]\n",
    "test = f.retrieve_attributes(test_path) \n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model testing and validating: BasicCNN1\n",
      "-- epoch 0\n",
      "12\n",
      "11\n",
      "9\n",
      "27\n",
      "17\n",
      "26\n",
      "Train loss: 0.1879569947719574\n",
      "Train accuracy: 1.0\n",
      "Test loss: 0.06265233159065246\n",
      "Test accuracy: 1.0\n",
      "-- epoch 1\n",
      "17\n",
      "18\n",
      "13\n",
      "14\n",
      "17\n",
      "23\n",
      "Train loss: 0.1879569947719574\n",
      "Train accuracy: 1.0\n",
      "Test loss: 0.06265233159065246\n",
      "Test accuracy: 1.0\n",
      "-- epoch 2\n",
      "23\n",
      "25\n",
      "14\n",
      "12\n",
      "10\n",
      "18\n",
      "Train loss: 0.1879569947719574\n",
      "Train accuracy: 1.0\n",
      "Test loss: 0.06265233159065246\n",
      "Test accuracy: 1.0\n",
      "-- epoch 3\n",
      "32\n",
      "11\n",
      "8\n",
      "22\n",
      "12\n",
      "17\n",
      "Train loss: 0.1879569947719574\n",
      "Train accuracy: 1.0\n",
      "Test loss: 0.06265233159065246\n",
      "Test accuracy: 1.0\n",
      "-- epoch 4\n",
      "17\n",
      "16\n",
      "19\n",
      "22\n",
      "9\n",
      "19\n",
      "Train loss: 0.1879569947719574\n",
      "Train accuracy: 1.0\n",
      "Test loss: 0.06265233159065246\n",
      "Test accuracy: 1.0\n",
      "-- epoch 5\n",
      "11\n",
      "18\n",
      "16\n",
      "20\n",
      "19\n",
      "18\n",
      "Train loss: 0.1879569947719574\n",
      "Train accuracy: 1.0\n",
      "Test loss: 0.06265233159065246\n",
      "Test accuracy: 1.0\n",
      "-- epoch 6\n",
      "20\n",
      "16\n",
      "22\n",
      "5\n",
      "20\n",
      "19\n",
      "Train loss: 0.1879569947719574\n",
      "Train accuracy: 1.0\n",
      "Test loss: 0.06265233159065246\n",
      "Test accuracy: 1.0\n",
      "-- epoch 7\n",
      "21\n",
      "12\n",
      "20\n",
      "8\n",
      "30\n",
      "11\n",
      "Train loss: 0.1879569947719574\n",
      "Train accuracy: 1.0\n",
      "Test loss: 0.06265233159065246\n",
      "Test accuracy: 1.0\n",
      "-- epoch 8\n",
      "7\n",
      "15\n",
      "18\n",
      "18\n",
      "23\n",
      "21\n",
      "Train loss: 0.1879569947719574\n",
      "Train accuracy: 1.0\n",
      "Test loss: 0.06265233159065246\n",
      "Test accuracy: 1.0\n",
      "-- epoch 9\n",
      "16\n",
      "7\n",
      "15\n",
      "20\n",
      "24\n",
      "20\n",
      "Train loss: 0.1879569947719574\n",
      "Train accuracy: 1.0\n",
      "Test loss: 0.06265233159065246\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model1 = m.BasicCNN1()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model1.parameters(), lr=0.001)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cfg = {\n",
    "    'num_epochs': 10,\n",
    "    'num_classes': 2,\n",
    "    'batch_size': train_loader.batch_size,\n",
    "    'test_size': len(train_loader.dataset),\n",
    "    'test_size': len(test_loader.dataset),\n",
    "    'criterion': criterion,\n",
    "    'optimizer': optimizer,\n",
    "    'device': device,\n",
    "    'model': model1,\n",
    "    }\n",
    "\n",
    "# arguments: self, model, loader: list, criterion, optimizer, device, cfg: dict\n",
    "t = train_eval.TrainTestModels(model=model1, loader=[train_loader, test_loader], criterion=criterion, optimizer=optimizer, device=device, cfg=cfg)\n",
    "t.epoch_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes ['params'] assigned to /Users/adamkurth/Documents/vscode/CXFEL/cxls_hitfinder/images/peaks/01/empty_peak_01_00020.h5\n"
     ]
    }
   ],
   "source": [
    "test_peaks = myPaths.get_peak_image_paths(dataset=dataset)[0]\n",
    "test_water = myPaths.get_peaks_water_overlay_image_paths(dataset=dataset)[0]\n",
    "test_overlay = myPaths.get_peaks_water_overlay_image_paths(dataset=dataset)[0]\n",
    "param1, param2 = (0.5, 9000), (0.5, 9000, True)\n",
    "f.assign_attributes(file_path=test_peaks, params=param1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
