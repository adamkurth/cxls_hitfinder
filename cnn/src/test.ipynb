{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clen: 1.5, photon_energy: 6000\n",
      "Paths refreshed for dataset 01.\n",
      "Directory: peaks/01\n",
      "\tTotal files: 73\n",
      "\tNormal images: 39\n",
      "\tEmpty images: 34\n",
      "Directory: labels/01\n",
      "\tTotal files: 73\n",
      "\tNormal images: 39\n",
      "\tEmpty images: 34\n",
      "Directory: peaks_water_overlay/01\n",
      "\tTotal files: 73\n",
      "\tNormal images: 39\n",
      "\tEmpty images: 34\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from glob import glob\n",
    "from pkg import *\n",
    "\n",
    "# dataset_num = input(\"Enter dataset number: \")\n",
    "# dataset = dataset_num.zfill(2) # string (ex '01')\n",
    "dataset = '01'\n",
    "\n",
    "myPaths = path.PathManager(dataset=dataset)\n",
    "myProcessor = process.Processor(paths=myPaths, dataset=dataset)\n",
    "clen, photon_energy = myProcessor.get_parameters()\n",
    "print(f\"clen: {clen}, photon_energy: {photon_energy}\")\n",
    "\n",
    "f.get_counts(paths=myPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths refreshed for dataset 01.\n",
      "Directory: peaks/01\n",
      "\tTotal files: 73\n",
      "\tNormal images: 39\n",
      "\tEmpty images: 34\n",
      "Directory: labels/01\n",
      "\tTotal files: 73\n",
      "\tNormal images: 39\n",
      "\tEmpty images: 34\n",
      "Directory: peaks_water_overlay/01\n",
      "\tTotal files: 73\n",
      "\tNormal images: 39\n",
      "\tEmpty images: 34\n"
     ]
    }
   ],
   "source": [
    "f.get_counts(paths=myPaths)\n",
    "# %run process_directory.py ../../images  --percent_empty 0.5 \n",
    "# f.get_counts(paths=myPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths refreshed for dataset 01.\n",
      "Directory: peaks/01\n",
      "\tTotal files: 73\n",
      "\tNormal images: 39\n",
      "\tEmpty images: 34\n",
      "Directory: labels/01\n",
      "\tTotal files: 73\n",
      "\tNormal images: 39\n",
      "\tEmpty images: 34\n",
      "Directory: peaks_water_overlay/01\n",
      "\tTotal files: 73\n",
      "\tNormal images: 39\n",
      "\tEmpty images: 34\n",
      "Paths refreshed for dataset 01.\n",
      "Actual percentage of empty images: 46.57534246575342% across peaks, water_overlays, and labels directories.\n",
      "\n",
      "All files in dataset 01 of type 'peak' have matching attributes.\n",
      "All files in dataset 01 of type 'label' have matching attributes.\n",
      "All files in dataset 01 of type 'overlay' have matching attributes.\n",
      "All files in dataset 01 of type 'background' have matching attributes.\n",
      "Dataset 01 authenticated.\n",
      "\n",
      "Final dataset sizes - Peaks: 73, Labels: 73, Overlays: 73\n",
      "All files in dataset 01 of type 'peak' have matching attributes.\n",
      "All files in dataset 01 of type 'overlay' have matching attributes.\n",
      "All files in dataset 01 of type 'label' have matching attributes.\n",
      "\n",
      "Data prepared.\n",
      "Train size: 58\n",
      "Test size: 15\n",
      "Batch size: 10\n",
      "Number of batches in train_loader: 6 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDataManager = data.DatasetManager(paths=myPaths, dataset=dataset, parameters=[clen,photon_energy], transform=None)\n",
    "\n",
    "# peak, label, overlay are valid types\n",
    "clen, photon_energy = myProcessor.get_parameters()\n",
    "\n",
    "f.check_attributes(paths=myPaths, dataset=dataset, type='peak', clen=clen, photon_energy=photon_energy) \n",
    "f.check_attributes(paths=myPaths, dataset=dataset, type='overlay', clen=clen, photon_energy=photon_energy)\n",
    "f.check_attributes(paths=myPaths, dataset=dataset, type='label', clen=clen, photon_energy=photon_energy)\n",
    "\n",
    "train_loader, test_loader = f.prepare(data_manager=myDataManager, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files in dataset 01 of type 'peak' have matching attributes.\n",
      "{'clen': 1.5, 'peak': False, 'photon_energy': 6000}\n"
     ]
    }
   ],
   "source": [
    "f.check_attributes(paths=myPaths, dataset=dataset, type='peak', clen=clen, photon_energy=photon_energy)\n",
    "test_path = myPaths.get_peak_image_paths(dataset)[0]\n",
    "test = f.retrieve_attributes(test_path) \n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model testing and validating: BasicCNN1\n",
      "-- epoch 0\n",
      "18\n",
      "24\n",
      "17\n",
      "11\n",
      "27\n",
      "9\n",
      "Train loss: 0.1879569947719574\n",
      "Train accuracy: 1.0\n",
      "Test loss: 0.06265233159065246\n",
      "Test accuracy: 1.0\n",
      "-- epoch 1\n"
     ]
    }
   ],
   "source": [
    "model1 = m.BasicCNN1()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model1.parameters(), lr=0.001)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cfg = {\n",
    "    'num_epochs': 10,\n",
    "    'num_classes': 2,\n",
    "    'batch_size': train_loader.batch_size,\n",
    "    'test_size': len(train_loader.dataset),\n",
    "    'test_size': len(test_loader.dataset),\n",
    "    'criterion': criterion,\n",
    "    'optimizer': optimizer,\n",
    "    'device': device,\n",
    "    'model': model1,\n",
    "    }\n",
    "\n",
    "# arguments: self, model, loader: list, criterion, optimizer, device, cfg: dict\n",
    "t = train_eval.TrainTestModels(model=model1, loader=[train_loader, test_loader], criterion=criterion, optimizer=optimizer, device=device, cfg=cfg)\n",
    "t.epoch_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes ['params'] assigned to /Users/adamkurth/Documents/vscode/CXFEL/cxls_hitfinder/images/peaks/01/empty_peak_01_00020.h5\n"
     ]
    }
   ],
   "source": [
    "test_peaks = myPaths.get_peak_image_paths(dataset=dataset)[0]\n",
    "test_water = myPaths.get_peaks_water_overlay_image_paths(dataset=dataset)[0]\n",
    "test_overlay = myPaths.get_peaks_water_overlay_image_paths(dataset=dataset)[0]\n",
    "param1, param2 = (0.5, 9000), (0.5, 9000, True)\n",
    "f.assign_attributes(file_path=test_peaks, params=param1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
