{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ResNet50 Demo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms.functional import to_pil_image, to_tensor\n",
    "from  torchvision import transforms\n",
    "from pkg import c, m, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_sim did not move any files\n",
      "\n",
      "\n",
      "Number of Peak Images:  54 Number of Water Images 54\n",
      "Peak images path: /Users/adamkurth/Documents/vscode/CXFEL/cxls_hitfinder/images/peaks\n",
      "Water images path: /Users/adamkurth/Documents/vscode/CXFEL/cxls_hitfinder/images/data\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Instances\"\"\"\n",
    "paths = c.PathManager()\n",
    "dataset = c.PeakImageDataset(paths=paths, transform=None, augment=True)\n",
    "prep = c.DataPreparation(paths=paths, batch_size=5)\n",
    "p = c.PeakThresholdProcessor(threshold_value=100)\n",
    "\n",
    "\"\"\"Clean sim/ directory\"\"\"\n",
    "paths.clean_sim() # moves all .err, .out, .sh files sim_specs\n",
    "\n",
    "\"\"\"Checks\"\"\"\n",
    "peak_paths = paths.__get_peak_images_paths__()\n",
    "water_paths = paths.__get_water_images_paths__()\n",
    "print('Number of Peak Images: ', len(peak_paths), 'Number of Water Images', len(water_paths))\n",
    "\n",
    "print(\"Peak images path:\", paths.peak_images_dir)\n",
    "print(\"Water images path:\", paths.water_images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared.\n",
      "Train size: 43\n",
      "Test size: 11\n",
      "Batch size: 5\n",
      "Number of batches: 9 \n",
      "\n",
      "\n",
      "Criterion:  CrossEntropyLoss() CrossEntropyLoss()\n",
      "Optimizer: \n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Learning rate:  0.001\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Train/Test Data Loaders\"\"\"\n",
    "train_loader, test_loader = prep.prep_data()\n",
    "\n",
    "\"\"\"Protein Mapping\"\"\"\n",
    "protein_to_idx = {\n",
    "    '1IC6': 0,\n",
    "    # To be developed\n",
    "}\n",
    "\n",
    "\"\"\"Models\"\"\"\n",
    "model_res50 = m.CustomResNet50(num_proteins=3, num_camlengths=3, heatmap_size=(2163,2069))\n",
    "\n",
    "\"\"\"Loss/Optimizer\"\"\"\n",
    "criterion_protein = criterion_camlength = torch.nn.CrossEntropyLoss()\n",
    "criterion_peak = torch.nn.MSELoss() # for heatmap prediction, MSE is more appropriate\n",
    "optimizer = torch.optim.Adam(model_res50.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Criterion: \", criterion_protein, criterion_camlength)\n",
    "print(\"Optimizer: \\n\", optimizer)\n",
    "print(\"Learning rate: \", optimizer.param_groups[0]['lr'])\n",
    "\n",
    "\"\"\"Initial Setup\"\"\"\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def generate_heatmaps(batch_images, processor):\n",
    "    batch_heatmaps = []\n",
    "    for image_tensor in batch_images:\n",
    "        peak_coords = processor._process_image(image_tensor)  # Process each image\n",
    "        heatmap = np.zeros(image_tensor.squeeze().shape)\n",
    "        for y, x in peak_coords:\n",
    "            heatmap[y, x] = 1  # Set peak positions to 1\n",
    "        heatmap_tensor = torch.tensor(heatmap).unsqueeze(0)  # Convert to tensor and adjust shape\n",
    "        batch_heatmaps.append(heatmap_tensor)\n",
    "    return torch.stack(batch_heatmaps) # return batch of heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 17:40:20,567 - INFO - Staring training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 17:40:21,151 - INFO - Epoch 1/1 - First batch label structure: ('1IC6', '1IC6', '1IC6', '1IC6', '1IC6') with type <class 'tuple'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label structure: ('1IC6', '1IC6', '1IC6', '1IC6', '1IC6') <class 'tuple'>\n",
      "\n",
      "\n",
      "[('1IC6', '1IC6', '1IC6', '1IC6', '1IC6'), tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100], dtype=torch.float64), tensor([0, 0, 0, 0, 0])]\n",
      "Label structure: tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100], dtype=torch.float64) <class 'torch.Tensor'>\n",
      "\n",
      "\n",
      "[('1IC6', '1IC6', '1IC6', '1IC6', '1IC6'), tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100], dtype=torch.float64), tensor([0, 0, 0, 0, 0])]\n",
      "Label structure: tensor([0, 0, 0, 0, 0]) <class 'torch.Tensor'>\n",
      "\n",
      "\n",
      "[('1IC6', '1IC6', '1IC6', '1IC6', '1IC6'), tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100], dtype=torch.float64), tensor([0, 0, 0, 0, 0])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamkurth/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([5, 1, 2163, 2069])) that is different to the input size (torch.Size([5, 2163, 2069])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found dtype Double but expected Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# compute total loss  \u001b[39;00m\n\u001b[1;32m     48\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m protein_loss \u001b[38;5;241m+\u001b[39m camlength_loss \u001b[38;5;241m+\u001b[39m peak_heatmap_loss\n\u001b[0;32m---> 49\u001b[0m \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     51\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m total_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found dtype Double but expected Float"
     ]
    }
   ],
   "source": [
    "\"\"\"Training\"\"\"\n",
    "logging.info('Staring training...')\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_res50.train()\n",
    "    running_loss = 0.0\n",
    "    batch_counter = 0\n",
    "    \n",
    "    for batch_index, ((peak_images, water_images), labels) in enumerate(train_loader, start=1):\n",
    "        if batch_index == 1:\n",
    "            logging.info(f\"Epoch {epoch+1}/{num_epochs} - First batch label structure: {labels[0]} with type {type(labels[0])}\")\n",
    "        \n",
    "        for label in labels:\n",
    "            print(f\"Label structure: {label} {type(label)}\\n\\n\")\n",
    "            print(labels) # gives tuple of 3 tensors\n",
    "        \n",
    "        # Extract the protein identifiers assuming they are always the first element in the label tuple\n",
    "        protein_identifiers = labels[0] # gives tuple ('1IC6', '1IC6', '1IC6', '1IC6', '1IC6')\n",
    "\n",
    "        try:            \n",
    "            # generate heatmaps for the batch\n",
    "            # label_heatmaps = prep.generate_heatmaps(batch_images=peak_images, processor=p)\n",
    "            label_heatmaps = prep.generate_heatmaps(batch_images=peak_images, processor=p)\n",
    "            label_heatmaps = label_heatmaps.to(peak_images.device) # ensure the heatmap tensor is on the correct device\n",
    "            \n",
    "            # protein/camlen \n",
    "            label_protein = torch.tensor([protein_to_idx[label] for label in labels[0]], dtype=torch.long).to(peak_images.device)\n",
    "            label_cam_len = labels[2].to(dtype=torch.long)\n",
    "            \n",
    "        except KeyError as e:\n",
    "            logging.error(f\"KeyError with label: {e}\")\n",
    "            print(f\"KeyError with label: {e}\")\n",
    "            print(labels[:5])\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # multi-task learning: predicting protein and camlength\n",
    "        protein_pred, camlen_pred, peak_heatmap_pred = model_res50((peak_images, water_images))\n",
    "        \n",
    "        # losses\n",
    "        protein_loss = criterion_protein(protein_pred, label_protein)\n",
    "        camlength_loss = criterion_camlength(camlen_pred, label_cam_len)\n",
    "        peak_heatmap_loss = criterion_peak(peak_heatmap_pred, label_heatmaps)\n",
    "        \n",
    "        # compute total loss  \n",
    "        total_loss = protein_loss + camlength_loss + peak_heatmap_loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += total_loss.item()\n",
    "        batch_counter += 1\n",
    "\n",
    "        if (batch_index + 1) % 10 == 0:  # Log every 10 batches\n",
    "            logging.info(f'Epoch {epoch+1}, Batch {batch_index + 1}: Loss = {running_loss/(batch_index+1)}')\n",
    "\n",
    "    avg_loss_train = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss_train)\n",
    "    logging.info(f'Epoch {epoch+1} Training Completed. Avg Loss: {avg_loss_train:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak Image Shape: torch.Size([1, 2163, 2069]), Water Image Shape: torch.Size([1, 2163, 2069])\n",
      "Protein: 1IC6, Camera Length: 0.01, Label Camera Length: 0\n",
      "Peak Image Shape: torch.Size([1, 2163, 2069]), Water Image Shape: torch.Size([1, 2163, 2069])\n",
      "Protein: 1IC6, Camera Length: 0.01, Label Camera Length: 0\n",
      "Peak Image Shape: torch.Size([1, 2163, 2069]), Water Image Shape: torch.Size([1, 2163, 2069])\n",
      "Protein: 1IC6, Camera Length: 0.01, Label Camera Length: 0\n",
      "Peak Image Shape: torch.Size([1, 2163, 2069]), Water Image Shape: torch.Size([1, 2163, 2069])\n",
      "Protein: 1IC6, Camera Length: 0.01, Label Camera Length: 0\n",
      "Peak Image Shape: torch.Size([1, 2163, 2069]), Water Image Shape: torch.Size([1, 2163, 2069])\n",
      "Protein: 1IC6, Camera Length: 0.01, Label Camera Length: 0\n",
      "Peak Image Shape: torch.Size([1, 2163, 2069]), Water Image Shape: torch.Size([1, 2163, 2069])\n",
      "Protein: 1IC6, Camera Length: 0.01, Label Camera Length: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 11:49:12,816 - INFO - Test Loss: 0.0000, Protein Accuracy: 1.0000, Camera Length Accuracy: 1.0000\n",
      "2024-03-05 11:49:12,817 - INFO - Training completed.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Testing\"\"\"\n",
    "logging.info('Starting testing...')\n",
    "model_res50.eval()\n",
    "test_loss = 0 \n",
    "correct_protein = 0\n",
    "correct_camlen = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (peak_images, water_images), labels in test_loader:\n",
    "        # labels\n",
    "        labels_protein = torch.tensor([protein_to_idx[protein] for protein in labels[0]], dtype=torch.long).to(peak_images.device)\n",
    "        labels_camlen = labels[2].to(dtype=torch.long).to(peak_images.device)\n",
    "        label_heatmaps = prep.generate_heatmaps(batch_images=peak_images, processor=p).to(peak_images.device)\n",
    "        # model outputs\n",
    "        protein_pred, camlength_pred, peak_heatmap_pred = model_res50((peak_images, water_images))\n",
    "        # losses\n",
    "        loss_protein = criterion_protein(protein_pred, labels_protein)\n",
    "        loss_camlen = criterion_camlength(camlength_pred, labels_camlen)\n",
    "        loss_peak = criterion_peak(peak_heatmap_pred, label_heatmaps)\n",
    "        \n",
    "        # adjust\n",
    "        test_loss = loss_protein + loss_camlen # camlen and protein\n",
    "        total_peak_loss = loss_peak.item() # peaks \n",
    "        \n",
    "        # predictions\n",
    "        _, predicted_protein = torch.max(protein_pred, 1)\n",
    "        _, predicted_camlen = torch.max(camlength_pred, 1)\n",
    "        # _, predicted_peak = torch.max(peak_heatmap_pred, 1)\n",
    "        \n",
    "        # calculate accuracy\n",
    "        correct_protein += (predicted_protein == labels_protein).sum().item()\n",
    "        correct_camlen += (predicted_camlen == labels_camlen).sum().item()\n",
    "        total += labels_protein.size(0)\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_losses.append(avg_test_loss)\n",
    "    protein_accuracy = correct_protein / total\n",
    "    camlength_accuracy = correct_camlen / total\n",
    "\n",
    "    logging.info(f\"Test Loss: {avg_test_loss:.4f}, Protein Accuracy: {protein_accuracy:.4f}, Camera Length Accuracy: {camlength_accuracy:.4f}\")\n",
    "    \n",
    "logging.info('Testing completed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtrain_losses\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(test_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTesting Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Plotting\"\"\"\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs+1), test_losses, label='Testing Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Testing Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
