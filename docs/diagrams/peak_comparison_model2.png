digraph {
	graph [size="154.35,154.35"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2616756950016 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	2616646059296 [label=AddmmBackward0]
	2616614020592 -> 2616646059296
	2616757414608 [label="fc2.bias
 (1)" fillcolor=lightblue]
	2616757414608 -> 2616614020592
	2616614020592 [label=AccumulateGrad]
	2616757385200 -> 2616646059296
	2616757385200 [label=ReluBackward0]
	2616757379536 -> 2616757385200
	2616757379536 [label=AddmmBackward0]
	2616757381792 -> 2616757379536
	2616757414688 [label="fc1.bias
 (512)" fillcolor=lightblue]
	2616757414688 -> 2616757381792
	2616757381792 [label=AccumulateGrad]
	2616757376800 -> 2616757379536
	2616757376800 [label=NativeDropoutBackward0]
	2616757378048 -> 2616757376800
	2616757378048 [label=ViewBackward0]
	2616757376560 -> 2616757378048
	2616757376560 [label=MeanBackward1]
	2616757376416 -> 2616757376560
	2616757376416 [label=ReluBackward0]
	2616757376176 -> 2616757376416
	2616757376176 [label=AddBackward0]
	2616757376128 -> 2616757376176
	2616757376128 [label=CudnnBatchNormBackward0]
	2616645893808 -> 2616757376128
	2616645893808 [label=ConvolutionBackward0]
	2616757375648 -> 2616645893808
	2616757375648 [label=ReluBackward0]
	2616757375360 -> 2616757375648
	2616757375360 [label=CudnnBatchNormBackward0]
	2616757375120 -> 2616757375360
	2616757375120 [label=ConvolutionBackward0]
	2616757374832 -> 2616757375120
	2616757374832 [label=ReluBackward0]
	2616757374496 -> 2616757374832
	2616757374496 [label=CudnnBatchNormBackward0]
	2616757374256 -> 2616757374496
	2616757374256 [label=ConvolutionBackward0]
	2616757377856 -> 2616757374256
	2616757377856 [label=ReluBackward0]
	2616757373632 -> 2616757377856
	2616757373632 [label=AddBackward0]
	2616757373344 -> 2616757373632
	2616757373344 [label=CudnnBatchNormBackward0]
	2616757372912 -> 2616757373344
	2616757372912 [label=ConvolutionBackward0]
	2616757372528 -> 2616757372912
	2616757372528 [label=ReluBackward0]
	2616757372288 -> 2616757372528
	2616757372288 [label=CudnnBatchNormBackward0]
	2616757372096 -> 2616757372288
	2616757372096 [label=ConvolutionBackward0]
	2616757371568 -> 2616757372096
	2616757371568 [label=ReluBackward0]
	2616757371280 -> 2616757371568
	2616757371280 [label=CudnnBatchNormBackward0]
	2616757371088 -> 2616757371280
	2616757371088 [label=ConvolutionBackward0]
	2616757373488 -> 2616757371088
	2616757373488 [label=ReluBackward0]
	2616644787392 -> 2616757373488
	2616644787392 [label=AddBackward0]
	2616633225088 -> 2616644787392
	2616633225088 [label=CudnnBatchNormBackward0]
	2616646390288 -> 2616633225088
	2616646390288 [label=ConvolutionBackward0]
	2616634308544 -> 2616646390288
	2616634308544 [label=ReluBackward0]
	2616645346992 -> 2616634308544
	2616645346992 [label=CudnnBatchNormBackward0]
	2616645341376 -> 2616645346992
	2616645341376 [label=ConvolutionBackward0]
	2616645350736 -> 2616645341376
	2616645350736 [label=ReluBackward0]
	2616645684336 -> 2616645350736
	2616645684336 [label=CudnnBatchNormBackward0]
	2616645133760 -> 2616645684336
	2616645133760 [label=ConvolutionBackward0]
	2616757232416 -> 2616645133760
	2616757232416 [label=ReluBackward0]
	2616757229488 -> 2616757232416
	2616757229488 [label=AddBackward0]
	2616757239376 -> 2616757229488
	2616757239376 [label=CudnnBatchNormBackward0]
	2616757230880 -> 2616757239376
	2616757230880 [label=ConvolutionBackward0]
	2616757229296 -> 2616757230880
	2616757229296 [label=ReluBackward0]
	2616757234624 -> 2616757229296
	2616757234624 [label=CudnnBatchNormBackward0]
	2616757228480 -> 2616757234624
	2616757228480 [label=ConvolutionBackward0]
	2616757239424 -> 2616757228480
	2616757239424 [label=ReluBackward0]
	2616757239088 -> 2616757239424
	2616757239088 [label=CudnnBatchNormBackward0]
	2616757238896 -> 2616757239088
	2616757238896 [label=ConvolutionBackward0]
	2616757239664 -> 2616757238896
	2616757239664 [label=ReluBackward0]
	2616757238272 -> 2616757239664
	2616757238272 [label=AddBackward0]
	2616757238080 -> 2616757238272
	2616757238080 [label=CudnnBatchNormBackward0]
	2616757237840 -> 2616757238080
	2616757237840 [label=ConvolutionBackward0]
	2616757237456 -> 2616757237840
	2616757237456 [label=ReluBackward0]
	2616757237168 -> 2616757237456
	2616757237168 [label=CudnnBatchNormBackward0]
	2616757236880 -> 2616757237168
	2616757236880 [label=ConvolutionBackward0]
	2616757236592 -> 2616757236880
	2616757236592 [label=ReluBackward0]
	2616757236160 -> 2616757236592
	2616757236160 [label=CudnnBatchNormBackward0]
	2616757235968 -> 2616757236160
	2616757235968 [label=ConvolutionBackward0]
	2616757238224 -> 2616757235968
	2616757238224 [label=ReluBackward0]
	2616757235488 -> 2616757238224
	2616757235488 [label=AddBackward0]
	2616757235296 -> 2616757235488
	2616757235296 [label=CudnnBatchNormBackward0]
	2616757235008 -> 2616757235296
	2616757235008 [label=ConvolutionBackward0]
	2616757234528 -> 2616757235008
	2616757234528 [label=ReluBackward0]
	2616757234240 -> 2616757234528
	2616757234240 [label=CudnnBatchNormBackward0]
	2616757233952 -> 2616757234240
	2616757233952 [label=ConvolutionBackward0]
	2616757233472 -> 2616757233952
	2616757233472 [label=ReluBackward0]
	2616757233280 -> 2616757233472
	2616757233280 [label=CudnnBatchNormBackward0]
	2616757232800 -> 2616757233280
	2616757232800 [label=ConvolutionBackward0]
	2616757223488 -> 2616757232800
	2616757223488 [label=ReluBackward0]
	2616757232320 -> 2616757223488
	2616757232320 [label=AddBackward0]
	2616757231936 -> 2616757232320
	2616757231936 [label=CudnnBatchNormBackward0]
	2616757231888 -> 2616757231936
	2616757231888 [label=ConvolutionBackward0]
	2616757231504 -> 2616757231888
	2616757231504 [label=ReluBackward0]
	2616757231120 -> 2616757231504
	2616757231120 [label=CudnnBatchNormBackward0]
	2616757230976 -> 2616757231120
	2616757230976 [label=ConvolutionBackward0]
	2616757230496 -> 2616757230976
	2616757230496 [label=ReluBackward0]
	2616757230112 -> 2616757230496
	2616757230112 [label=CudnnBatchNormBackward0]
	2616757229824 -> 2616757230112
	2616757229824 [label=ConvolutionBackward0]
	2616757232272 -> 2616757229824
	2616757232272 [label=ReluBackward0]
	2616757229200 -> 2616757232272
	2616757229200 [label=AddBackward0]
	2616757228912 -> 2616757229200
	2616757228912 [label=CudnnBatchNormBackward0]
	2616757228528 -> 2616757228912
	2616757228528 [label=ConvolutionBackward0]
	2616757228048 -> 2616757228528
	2616757228048 [label=ReluBackward0]
	2616757227664 -> 2616757228048
	2616757227664 [label=CudnnBatchNormBackward0]
	2616757227376 -> 2616757227664
	2616757227376 [label=ConvolutionBackward0]
	2616757226896 -> 2616757227376
	2616757226896 [label=ReluBackward0]
	2616757226512 -> 2616757226896
	2616757226512 [label=CudnnBatchNormBackward0]
	2616757226224 -> 2616757226512
	2616757226224 [label=ConvolutionBackward0]
	2616757229104 -> 2616757226224
	2616757229104 [label=ReluBackward0]
	2616757225552 -> 2616757229104
	2616757225552 [label=AddBackward0]
	2616757225360 -> 2616757225552
	2616757225360 [label=CudnnBatchNormBackward0]
	2616757224976 -> 2616757225360
	2616757224976 [label=ConvolutionBackward0]
	2616757224448 -> 2616757224976
	2616757224448 [label=ReluBackward0]
	2616757224160 -> 2616757224448
	2616757224160 [label=CudnnBatchNormBackward0]
	2616757224016 -> 2616757224160
	2616757224016 [label=ConvolutionBackward0]
	2616757223584 -> 2616757224016
	2616757223584 [label=ReluBackward0]
	2616512423504 -> 2616757223584
	2616512423504 [label=CudnnBatchNormBackward0]
	2616644573488 -> 2616512423504
	2616644573488 [label=ConvolutionBackward0]
	2616647287328 -> 2616644573488
	2616647287328 [label=ReluBackward0]
	2616647288720 -> 2616647287328
	2616647288720 [label=AddBackward0]
	2616647288480 -> 2616647288720
	2616647288480 [label=CudnnBatchNormBackward0]
	2616647288912 -> 2616647288480
	2616647288912 [label=ConvolutionBackward0]
	2616647288192 -> 2616647288912
	2616647288192 [label=ReluBackward0]
	2616647288528 -> 2616647288192
	2616647288528 [label=CudnnBatchNormBackward0]
	2616647286896 -> 2616647288528
	2616647286896 [label=ConvolutionBackward0]
	2616647300192 -> 2616647286896
	2616647300192 [label=ReluBackward0]
	2616647295440 -> 2616647300192
	2616647295440 [label=CudnnBatchNormBackward0]
	2616647301008 -> 2616647295440
	2616647301008 [label=ConvolutionBackward0]
	2616647288624 -> 2616647301008
	2616647288624 [label=ReluBackward0]
	2616647297600 -> 2616647288624
	2616647297600 [label=AddBackward0]
	2616647295104 -> 2616647297600
	2616647295104 [label=CudnnBatchNormBackward0]
	2616647294288 -> 2616647295104
	2616647294288 [label=ConvolutionBackward0]
	2616647302688 -> 2616647294288
	2616647302688 [label=ReluBackward0]
	2616647302256 -> 2616647302688
	2616647302256 [label=CudnnBatchNormBackward0]
	2616647302112 -> 2616647302256
	2616647302112 [label=ConvolutionBackward0]
	2616647301728 -> 2616647302112
	2616647301728 [label=ReluBackward0]
	2616647301296 -> 2616647301728
	2616647301296 [label=CudnnBatchNormBackward0]
	2616647300960 -> 2616647301296
	2616647300960 [label=ConvolutionBackward0]
	2616647295488 -> 2616647300960
	2616647295488 [label=ReluBackward0]
	2616647300528 -> 2616647295488
	2616647300528 [label=AddBackward0]
	2616647300288 -> 2616647300528
	2616647300288 [label=CudnnBatchNormBackward0]
	2616647298560 -> 2616647300288
	2616647298560 [label=ConvolutionBackward0]
	2616647299808 -> 2616647298560
	2616647299808 [label=ReluBackward0]
	2616647299328 -> 2616647299808
	2616647299328 [label=CudnnBatchNormBackward0]
	2616647299040 -> 2616647299328
	2616647299040 [label=ConvolutionBackward0]
	2616647298320 -> 2616647299040
	2616647298320 [label=ReluBackward0]
	2616647298272 -> 2616647298320
	2616647298272 [label=CudnnBatchNormBackward0]
	2616647297984 -> 2616647298272
	2616647297984 [label=ConvolutionBackward0]
	2616647300480 -> 2616647297984
	2616647300480 [label=ReluBackward0]
	2616647297120 -> 2616647300480
	2616647297120 [label=AddBackward0]
	2616647296928 -> 2616647297120
	2616647296928 [label=CudnnBatchNormBackward0]
	2616647296544 -> 2616647296928
	2616647296544 [label=ConvolutionBackward0]
	2616647295968 -> 2616647296544
	2616647295968 [label=ReluBackward0]
	2616647295920 -> 2616647295968
	2616647295920 [label=CudnnBatchNormBackward0]
	2616647295776 -> 2616647295920
	2616647295776 [label=ConvolutionBackward0]
	2616647295344 -> 2616647295776
	2616647295344 [label=ReluBackward0]
	2616647294864 -> 2616647295344
	2616647294864 [label=CudnnBatchNormBackward0]
	2616647294672 -> 2616647294864
	2616647294672 [label=ConvolutionBackward0]
	2616647294336 -> 2616647294672
	2616647294336 [label=ReluBackward0]
	2616647053616 -> 2616647294336
	2616647053616 [label=AddBackward0]
	2616647055440 -> 2616647053616
	2616647055440 [label=CudnnBatchNormBackward0]
	2616647056544 -> 2616647055440
	2616647056544 [label=ConvolutionBackward0]
	2616647055344 -> 2616647056544
	2616647055344 [label=ReluBackward0]
	2616647055488 -> 2616647055344
	2616647055488 [label=CudnnBatchNormBackward0]
	2616641927200 -> 2616647055488
	2616641927200 [label=ConvolutionBackward0]
	2616366031840 -> 2616641927200
	2616366031840 [label=ReluBackward0]
	2616645551248 -> 2616366031840
	2616645551248 [label=CudnnBatchNormBackward0]
	2616645553600 -> 2616645551248
	2616645553600 [label=ConvolutionBackward0]
	2616647056400 -> 2616645553600
	2616647056400 [label=ReluBackward0]
	2616645429296 -> 2616647056400
	2616645429296 [label=AddBackward0]
	2616645425936 -> 2616645429296
	2616645425936 [label=CudnnBatchNormBackward0]
	2616645429584 -> 2616645425936
	2616645429584 [label=ConvolutionBackward0]
	2616642235904 -> 2616645429584
	2616642235904 [label=ReluBackward0]
	2616757314432 -> 2616642235904
	2616757314432 [label=CudnnBatchNormBackward0]
	2616757306752 -> 2616757314432
	2616757306752 [label=ConvolutionBackward0]
	2616757320144 -> 2616757306752
	2616757320144 [label=ReluBackward0]
	2616757305744 -> 2616757320144
	2616757305744 [label=CudnnBatchNormBackward0]
	2616757313616 -> 2616757305744
	2616757313616 [label=ConvolutionBackward0]
	2616645422960 -> 2616757313616
	2616645422960 [label=ReluBackward0]
	2616757305552 -> 2616645422960
	2616757305552 [label=AddBackward0]
	2616757318896 -> 2616757305552
	2616757318896 [label=CudnnBatchNormBackward0]
	2616757309392 -> 2616757318896
	2616757309392 [label=ConvolutionBackward0]
	2616757311216 -> 2616757309392
	2616757311216 [label=ReluBackward0]
	2616757320624 -> 2616757311216
	2616757320624 [label=CudnnBatchNormBackward0]
	2616757313040 -> 2616757320624
	2616757313040 [label=ConvolutionBackward0]
	2616757307328 -> 2616757313040
	2616757307328 [label=ReluBackward0]
	2616757319616 -> 2616757307328
	2616757319616 [label=CudnnBatchNormBackward0]
	2616757316208 -> 2616757319616
	2616757316208 [label=ConvolutionBackward0]
	2616757311552 -> 2616757316208
	2616757311552 [label=MaxPool2DWithIndicesBackward0]
	2616612838112 -> 2616757311552
	2616612838112 [label=ReluBackward0]
	2616757321152 -> 2616612838112
	2616757321152 [label=CudnnBatchNormBackward0]
	2616757320960 -> 2616757321152
	2616757320960 [label=ConvolutionBackward0]
	2616757320576 -> 2616757320960
	2616757419648 [label="first_conv_layer.weight
 (64, 1, 7, 7)" fillcolor=lightblue]
	2616757419648 -> 2616757320576
	2616757320576 [label=AccumulateGrad]
	2616757321104 -> 2616757321152
	2616638969712 [label="feature_extractor.1.weight
 (64)" fillcolor=lightblue]
	2616638969712 -> 2616757321104
	2616757321104 [label=AccumulateGrad]
	2616757321440 -> 2616757321152
	2616647484352 [label="feature_extractor.1.bias
 (64)" fillcolor=lightblue]
	2616647484352 -> 2616757321440
	2616757321440 [label=AccumulateGrad]
	2616757312800 -> 2616757316208
	2616647486592 [label="feature_extractor.4.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	2616647486592 -> 2616757312800
	2616757312800 [label=AccumulateGrad]
	2616757318368 -> 2616757319616
	2616647486512 [label="feature_extractor.4.0.bn1.weight
 (64)" fillcolor=lightblue]
	2616647486512 -> 2616757318368
	2616757318368 [label=AccumulateGrad]
	2616757321680 -> 2616757319616
	2616647486672 [label="feature_extractor.4.0.bn1.bias
 (64)" fillcolor=lightblue]
	2616647486672 -> 2616757321680
	2616757321680 [label=AccumulateGrad]
	2616757309440 -> 2616757313040
	2616647487312 [label="feature_extractor.4.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2616647487312 -> 2616757309440
	2616757309440 [label=AccumulateGrad]
	2616757317312 -> 2616757320624
	2616647487232 [label="feature_extractor.4.0.bn2.weight
 (64)" fillcolor=lightblue]
	2616647487232 -> 2616757317312
	2616757317312 [label=AccumulateGrad]
	2616757306416 -> 2616757320624
	2616647487392 [label="feature_extractor.4.0.bn2.bias
 (64)" fillcolor=lightblue]
	2616647487392 -> 2616757306416
	2616757306416 [label=AccumulateGrad]
	2616757317888 -> 2616757309392
	2616647487872 [label="feature_extractor.4.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2616647487872 -> 2616757317888
	2616757317888 [label=AccumulateGrad]
	2616757307616 -> 2616757318896
	2616647487952 [label="feature_extractor.4.0.bn3.weight
 (256)" fillcolor=lightblue]
	2616647487952 -> 2616757307616
	2616757307616 [label=AccumulateGrad]
	2616757311264 -> 2616757318896
	2616647488032 [label="feature_extractor.4.0.bn3.bias
 (256)" fillcolor=lightblue]
	2616647488032 -> 2616757311264
	2616757311264 [label=AccumulateGrad]
	2616757316976 -> 2616757305552
	2616757316976 [label=CudnnBatchNormBackward0]
	2616757320672 -> 2616757316976
	2616757320672 [label=ConvolutionBackward0]
	2616757311552 -> 2616757320672
	2616757310304 -> 2616757320672
	2616647485632 [label="feature_extractor.4.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2616647485632 -> 2616757310304
	2616757310304 [label=AccumulateGrad]
	2616757311408 -> 2616757316976
	2616647485712 [label="feature_extractor.4.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	2616647485712 -> 2616757311408
	2616757311408 [label=AccumulateGrad]
	2616757309152 -> 2616757316976
	2616647485792 [label="feature_extractor.4.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	2616647485792 -> 2616757309152
	2616757309152 [label=AccumulateGrad]
	2616757307856 -> 2616757313616
	2616647488432 [label="feature_extractor.4.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	2616647488432 -> 2616757307856
	2616757307856 [label=AccumulateGrad]
	2616757317360 -> 2616757305744
	2616647488512 [label="feature_extractor.4.1.bn1.weight
 (64)" fillcolor=lightblue]
	2616647488512 -> 2616757317360
	2616757317360 [label=AccumulateGrad]
	2616757308672 -> 2616757305744
	2616647488592 [label="feature_extractor.4.1.bn1.bias
 (64)" fillcolor=lightblue]
	2616647488592 -> 2616757308672
	2616757308672 [label=AccumulateGrad]
	2616757318176 -> 2616757306752
	2616647489152 [label="feature_extractor.4.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2616647489152 -> 2616757318176
	2616757318176 [label=AccumulateGrad]
	2616757312848 -> 2616757314432
	2616647489072 [label="feature_extractor.4.1.bn2.weight
 (64)" fillcolor=lightblue]
	2616647489072 -> 2616757312848
	2616757312848 [label=AccumulateGrad]
	2616757313280 -> 2616757314432
	2616647489232 [label="feature_extractor.4.1.bn2.bias
 (64)" fillcolor=lightblue]
	2616647489232 -> 2616757313280
	2616757313280 [label=AccumulateGrad]
	2616639789744 -> 2616645429584
	2616647489712 [label="feature_extractor.4.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2616647489712 -> 2616639789744
	2616639789744 [label=AccumulateGrad]
	2616645422048 -> 2616645425936
	2616647489792 [label="feature_extractor.4.1.bn3.weight
 (256)" fillcolor=lightblue]
	2616647489792 -> 2616645422048
	2616645422048 [label=AccumulateGrad]
	2616645431024 -> 2616645425936
	2616647489872 [label="feature_extractor.4.1.bn3.bias
 (256)" fillcolor=lightblue]
	2616647489872 -> 2616645431024
	2616645431024 [label=AccumulateGrad]
	2616645422960 -> 2616645429296
	2616645423632 -> 2616645553600
	2616647490352 [label="feature_extractor.4.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	2616647490352 -> 2616645423632
	2616645423632 [label=AccumulateGrad]
	2616645553840 -> 2616645551248
	2616647490432 [label="feature_extractor.4.2.bn1.weight
 (64)" fillcolor=lightblue]
	2616647490432 -> 2616645553840
	2616645553840 [label=AccumulateGrad]
	2616645553552 -> 2616645551248
	2616647490512 [label="feature_extractor.4.2.bn1.bias
 (64)" fillcolor=lightblue]
	2616647490512 -> 2616645553552
	2616645553552 [label=AccumulateGrad]
	2616366025600 -> 2616641927200
	2616647491072 [label="feature_extractor.4.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2616647491072 -> 2616366025600
	2616366025600 [label=AccumulateGrad]
	2616647054768 -> 2616647055488
	2616647490992 [label="feature_extractor.4.2.bn2.weight
 (64)" fillcolor=lightblue]
	2616647490992 -> 2616647054768
	2616647054768 [label=AccumulateGrad]
	2616366029008 -> 2616647055488
	2616647491152 [label="feature_extractor.4.2.bn2.bias
 (64)" fillcolor=lightblue]
	2616647491152 -> 2616366029008
	2616366029008 [label=AccumulateGrad]
	2616647051648 -> 2616647056544
	2616647491632 [label="feature_extractor.4.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2616647491632 -> 2616647051648
	2616647051648 [label=AccumulateGrad]
	2616647057264 -> 2616647055440
	2616647491712 [label="feature_extractor.4.2.bn3.weight
 (256)" fillcolor=lightblue]
	2616647491712 -> 2616647057264
	2616647057264 [label=AccumulateGrad]
	2616647054816 -> 2616647055440
	2616647491792 [label="feature_extractor.4.2.bn3.bias
 (256)" fillcolor=lightblue]
	2616647491792 -> 2616647054816
	2616647054816 [label=AccumulateGrad]
	2616647056400 -> 2616647053616
	2616647051456 -> 2616647294672
	2616647492992 [label="feature_extractor.5.0.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2616647492992 -> 2616647051456
	2616647051456 [label=AccumulateGrad]
	2616647294768 -> 2616647294864
	2616647493072 [label="feature_extractor.5.0.bn1.weight
 (128)" fillcolor=lightblue]
	2616647493072 -> 2616647294768
	2616647294768 [label=AccumulateGrad]
	2616647295152 -> 2616647294864
	2616647493152 [label="feature_extractor.5.0.bn1.bias
 (128)" fillcolor=lightblue]
	2616647493152 -> 2616647295152
	2616647295152 [label=AccumulateGrad]
	2616647295200 -> 2616647295776
	2616647493712 [label="feature_extractor.5.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2616647493712 -> 2616647295200
	2616647295200 [label=AccumulateGrad]
	2616647295392 -> 2616647295920
	2616647493632 [label="feature_extractor.5.0.bn2.weight
 (128)" fillcolor=lightblue]
	2616647493632 -> 2616647295392
	2616647295392 [label=AccumulateGrad]
	2616647296112 -> 2616647295920
	2616647493792 [label="feature_extractor.5.0.bn2.bias
 (128)" fillcolor=lightblue]
	2616647493792 -> 2616647296112
	2616647296112 [label=AccumulateGrad]
	2616647296304 -> 2616647296544
	2616647494272 [label="feature_extractor.5.0.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2616647494272 -> 2616647296304
	2616647296304 [label=AccumulateGrad]
	2616647296736 -> 2616647296928
	2616647494352 [label="feature_extractor.5.0.bn3.weight
 (512)" fillcolor=lightblue]
	2616647494352 -> 2616647296736
	2616647296736 [label=AccumulateGrad]
	2616647296592 -> 2616647296928
	2616647494432 [label="feature_extractor.5.0.bn3.bias
 (512)" fillcolor=lightblue]
	2616647494432 -> 2616647296592
	2616647296592 [label=AccumulateGrad]
	2616647296784 -> 2616647297120
	2616647296784 [label=CudnnBatchNormBackward0]
	2616647295008 -> 2616647296784
	2616647295008 [label=ConvolutionBackward0]
	2616647294336 -> 2616647295008
	2616647295536 -> 2616647295008
	2616647492272 [label="feature_extractor.5.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2616647492272 -> 2616647295536
	2616647295536 [label=AccumulateGrad]
	2616647295728 -> 2616647296784
	2616647492352 [label="feature_extractor.5.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	2616647492352 -> 2616647295728
	2616647295728 [label=AccumulateGrad]
	2616647296448 -> 2616647296784
	2616647492432 [label="feature_extractor.5.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	2616647492432 -> 2616647296448
	2616647296448 [label=AccumulateGrad]
	2616647297408 -> 2616647297984
	2616647494832 [label="feature_extractor.5.1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2616647494832 -> 2616647297408
	2616647297408 [label=AccumulateGrad]
	2616647298080 -> 2616647298272
	2616647494912 [label="feature_extractor.5.1.bn1.weight
 (128)" fillcolor=lightblue]
	2616647494912 -> 2616647298080
	2616647298080 [label=AccumulateGrad]
	2616647298464 -> 2616647298272
	2616647494992 [label="feature_extractor.5.1.bn1.bias
 (128)" fillcolor=lightblue]
	2616647494992 -> 2616647298464
	2616647298464 [label=AccumulateGrad]
	2616647298656 -> 2616647299040
	2616647495552 [label="feature_extractor.5.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2616647495552 -> 2616647298656
	2616647298656 [label=AccumulateGrad]
	2616647299232 -> 2616647299328
	2616647495472 [label="feature_extractor.5.1.bn2.weight
 (128)" fillcolor=lightblue]
	2616647495472 -> 2616647299232
	2616647299232 [label=AccumulateGrad]
	2616647299616 -> 2616647299328
	2616647495632 [label="feature_extractor.5.1.bn2.bias
 (128)" fillcolor=lightblue]
	2616647495632 -> 2616647299616
	2616647299616 [label=AccumulateGrad]
	2616647299664 -> 2616647298560
	2616647496112 [label="feature_extractor.5.1.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2616647496112 -> 2616647299664
	2616647299664 [label=AccumulateGrad]
	2616647300096 -> 2616647300288
	2616647496192 [label="feature_extractor.5.1.bn3.weight
 (512)" fillcolor=lightblue]
	2616647496192 -> 2616647300096
	2616647300096 [label=AccumulateGrad]
	2616647298368 -> 2616647300288
	2616647496272 [label="feature_extractor.5.1.bn3.bias
 (512)" fillcolor=lightblue]
	2616647496272 -> 2616647298368
	2616647298368 [label=AccumulateGrad]
	2616647300480 -> 2616647300528
	2616647300816 -> 2616647300960
	2616647496752 [label="feature_extractor.5.2.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2616647496752 -> 2616647300816
	2616647300816 [label=AccumulateGrad]
	2616647301248 -> 2616647301296
	2616647496832 [label="feature_extractor.5.2.bn1.weight
 (128)" fillcolor=lightblue]
	2616647496832 -> 2616647301248
	2616647301248 [label=AccumulateGrad]
	2616647301536 -> 2616647301296
	2616647496912 [label="feature_extractor.5.2.bn1.bias
 (128)" fillcolor=lightblue]
	2616647496912 -> 2616647301536
	2616647301536 [label=AccumulateGrad]
	2616647301824 -> 2616647302112
	2616647497472 [label="feature_extractor.5.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2616647497472 -> 2616647301824
	2616647301824 [label=AccumulateGrad]
	2616647302064 -> 2616647302256
	2616647497392 [label="feature_extractor.5.2.bn2.weight
 (128)" fillcolor=lightblue]
	2616647497392 -> 2616647302064
	2616647302064 [label=AccumulateGrad]
	2616647302496 -> 2616647302256
	2616647497552 [label="feature_extractor.5.2.bn2.bias
 (128)" fillcolor=lightblue]
	2616647497552 -> 2616647302496
	2616647302496 [label=AccumulateGrad]
	2616647302784 -> 2616647294288
	2616647498032 [label="feature_extractor.5.2.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2616647498032 -> 2616647302784
	2616647302784 [label=AccumulateGrad]
	2616647301152 -> 2616647295104
	2616647498112 [label="feature_extractor.5.2.bn3.weight
 (512)" fillcolor=lightblue]
	2616647498112 -> 2616647301152
	2616647301152 [label=AccumulateGrad]
	2616647294528 -> 2616647295104
	2616647498192 [label="feature_extractor.5.2.bn3.bias
 (512)" fillcolor=lightblue]
	2616647498192 -> 2616647294528
	2616647294528 [label=AccumulateGrad]
	2616647295488 -> 2616647297600
	2616647298608 -> 2616647301008
	2616647498672 [label="feature_extractor.5.3.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2616647498672 -> 2616647298608
	2616647298608 [label=AccumulateGrad]
	2616647295632 -> 2616647295440
	2616647498752 [label="feature_extractor.5.3.bn1.weight
 (128)" fillcolor=lightblue]
	2616647498752 -> 2616647295632
	2616647295632 [label=AccumulateGrad]
	2616647297888 -> 2616647295440
	2616647498832 [label="feature_extractor.5.3.bn1.bias
 (128)" fillcolor=lightblue]
	2616647498832 -> 2616647297888
	2616647297888 [label=AccumulateGrad]
	2616647289872 -> 2616647286896
	2616647499392 [label="feature_extractor.5.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2616647499392 -> 2616647289872
	2616647289872 [label=AccumulateGrad]
	2616647299472 -> 2616647288528
	2616647499312 [label="feature_extractor.5.3.bn2.weight
 (128)" fillcolor=lightblue]
	2616647499312 -> 2616647299472
	2616647299472 [label=AccumulateGrad]
	2616647288048 -> 2616647288528
	2616647499472 [label="feature_extractor.5.3.bn2.bias
 (128)" fillcolor=lightblue]
	2616647499472 -> 2616647288048
	2616647288048 [label=AccumulateGrad]
	2616647288288 -> 2616647288912
	2616756945136 [label="feature_extractor.5.3.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2616756945136 -> 2616647288288
	2616647288288 [label=AccumulateGrad]
	2616647301392 -> 2616647288480
	2616756945216 [label="feature_extractor.5.3.bn3.weight
 (512)" fillcolor=lightblue]
	2616756945216 -> 2616647301392
	2616647301392 [label=AccumulateGrad]
	2616647288816 -> 2616647288480
	2616756945296 [label="feature_extractor.5.3.bn3.bias
 (512)" fillcolor=lightblue]
	2616756945296 -> 2616647288816
	2616647288816 [label=AccumulateGrad]
	2616647288624 -> 2616647288720
	2616647300384 -> 2616644573488
	2616756946496 [label="feature_extractor.6.0.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2616756946496 -> 2616647300384
	2616647300384 [label=AccumulateGrad]
	2616644575600 -> 2616512423504
	2616756946576 [label="feature_extractor.6.0.bn1.weight
 (256)" fillcolor=lightblue]
	2616756946576 -> 2616644575600
	2616644575600 [label=AccumulateGrad]
	2616646837456 -> 2616512423504
	2616756946656 [label="feature_extractor.6.0.bn1.bias
 (256)" fillcolor=lightblue]
	2616756946656 -> 2616646837456
	2616646837456 [label=AccumulateGrad]
	2616757223680 -> 2616757224016
	2616756947216 [label="feature_extractor.6.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2616756947216 -> 2616757223680
	2616757223680 [label=AccumulateGrad]
	2616757223920 -> 2616757224160
	2616756947136 [label="feature_extractor.6.0.bn2.weight
 (256)" fillcolor=lightblue]
	2616756947136 -> 2616757223920
	2616757223920 [label=AccumulateGrad]
	2616757224400 -> 2616757224160
	2616756947296 [label="feature_extractor.6.0.bn2.bias
 (256)" fillcolor=lightblue]
	2616756947296 -> 2616757224400
	2616757224400 [label=AccumulateGrad]
	2616757224640 -> 2616757224976
	2616756947776 [label="feature_extractor.6.0.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2616756947776 -> 2616757224640
	2616757224640 [label=AccumulateGrad]
	2616757225168 -> 2616757225360
	2616756947856 [label="feature_extractor.6.0.bn3.weight
 (1024)" fillcolor=lightblue]
	2616756947856 -> 2616757225168
	2616757225168 [label=AccumulateGrad]
	2616757225024 -> 2616757225360
	2616756947936 [label="feature_extractor.6.0.bn3.bias
 (1024)" fillcolor=lightblue]
	2616756947936 -> 2616757225024
	2616757225024 [label=AccumulateGrad]
	2616757225216 -> 2616757225552
	2616757225216 [label=CudnnBatchNormBackward0]
	2616757223872 -> 2616757225216
	2616757223872 [label=ConvolutionBackward0]
	2616647287328 -> 2616757223872
	2616646843888 -> 2616757223872
	2616756945776 [label="feature_extractor.6.0.downsample.0.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	2616756945776 -> 2616646843888
	2616646843888 [label=AccumulateGrad]
	2616757224256 -> 2616757225216
	2616756945856 [label="feature_extractor.6.0.downsample.1.weight
 (1024)" fillcolor=lightblue]
	2616756945856 -> 2616757224256
	2616757224256 [label=AccumulateGrad]
	2616757224928 -> 2616757225216
	2616756945936 [label="feature_extractor.6.0.downsample.1.bias
 (1024)" fillcolor=lightblue]
	2616756945936 -> 2616757224928
	2616757224928 [label=AccumulateGrad]
	2616757225792 -> 2616757226224
	2616756948336 [label="feature_extractor.6.1.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2616756948336 -> 2616757225792
	2616757225792 [label=AccumulateGrad]
	2616757226320 -> 2616757226512
	2616756948416 [label="feature_extractor.6.1.bn1.weight
 (256)" fillcolor=lightblue]
	2616756948416 -> 2616757226320
	2616757226320 [label=AccumulateGrad]
	2616757226800 -> 2616757226512
	2616756948496 [label="feature_extractor.6.1.bn1.bias
 (256)" fillcolor=lightblue]
	2616756948496 -> 2616757226800
	2616757226800 [label=AccumulateGrad]
	2616757227040 -> 2616757227376
	2616756949056 [label="feature_extractor.6.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2616756949056 -> 2616757227040
	2616757227040 [label=AccumulateGrad]
	2616757227568 -> 2616757227664
	2616756948976 [label="feature_extractor.6.1.bn2.weight
 (256)" fillcolor=lightblue]
	2616756948976 -> 2616757227568
	2616757227568 [label=AccumulateGrad]
	2616757227712 -> 2616757227664
	2616756949136 [label="feature_extractor.6.1.bn2.bias
 (256)" fillcolor=lightblue]
	2616756949136 -> 2616757227712
	2616757227712 [label=AccumulateGrad]
	2616757227904 -> 2616757228528
	2616756949616 [label="feature_extractor.6.1.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2616756949616 -> 2616757227904
	2616757227904 [label=AccumulateGrad]
	2616757228624 -> 2616757228912
	2616756949696 [label="feature_extractor.6.1.bn3.weight
 (1024)" fillcolor=lightblue]
	2616756949696 -> 2616757228624
	2616757228624 [label=AccumulateGrad]
	2616757228816 -> 2616757228912
	2616756949776 [label="feature_extractor.6.1.bn3.bias
 (1024)" fillcolor=lightblue]
	2616756949776 -> 2616757228816
	2616757228816 [label=AccumulateGrad]
	2616757229104 -> 2616757229200
	2616757229248 -> 2616757229824
	2616756950256 [label="feature_extractor.6.2.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2616756950256 -> 2616757229248
	2616757229248 [label=AccumulateGrad]
	2616757230016 -> 2616757230112
	2616756950336 [label="feature_extractor.6.2.bn1.weight
 (256)" fillcolor=lightblue]
	2616756950336 -> 2616757230016
	2616757230016 [label=AccumulateGrad]
	2616757230400 -> 2616757230112
	2616756950416 [label="feature_extractor.6.2.bn1.bias
 (256)" fillcolor=lightblue]
	2616756950416 -> 2616757230400
	2616757230400 [label=AccumulateGrad]
	2616757230592 -> 2616757230976
	2616756950976 [label="feature_extractor.6.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2616756950976 -> 2616757230592
	2616757230592 [label=AccumulateGrad]
	2616757231024 -> 2616757231120
	2616756950896 [label="feature_extractor.6.2.bn2.weight
 (256)" fillcolor=lightblue]
	2616756950896 -> 2616757231024
	2616757231024 [label=AccumulateGrad]
	2616757231312 -> 2616757231120
	2616756951056 [label="feature_extractor.6.2.bn2.bias
 (256)" fillcolor=lightblue]
	2616756951056 -> 2616757231312
	2616757231312 [label=AccumulateGrad]
	2616757231552 -> 2616757231888
	2616756951536 [label="feature_extractor.6.2.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2616756951536 -> 2616757231552
	2616757231552 [label=AccumulateGrad]
	2616757231840 -> 2616757231936
	2616756951616 [label="feature_extractor.6.2.bn3.weight
 (1024)" fillcolor=lightblue]
	2616756951616 -> 2616757231840
	2616757231840 [label=AccumulateGrad]
	2616757232080 -> 2616757231936
	2616756951696 [label="feature_extractor.6.2.bn3.bias
 (1024)" fillcolor=lightblue]
	2616756951696 -> 2616757232080
	2616757232080 [label=AccumulateGrad]
	2616757232272 -> 2616757232320
	2616757232560 -> 2616757232800
	2616756952176 [label="feature_extractor.6.3.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2616756952176 -> 2616757232560
	2616757232560 [label=AccumulateGrad]
	2616757233136 -> 2616757233280
	2616756952256 [label="feature_extractor.6.3.bn1.weight
 (256)" fillcolor=lightblue]
	2616756952256 -> 2616757233136
	2616757233136 [label=AccumulateGrad]
	2616757231984 -> 2616757233280
	2616756952336 [label="feature_extractor.6.3.bn1.bias
 (256)" fillcolor=lightblue]
	2616756952336 -> 2616757231984
	2616757231984 [label=AccumulateGrad]
	2616757233664 -> 2616757233952
	2616756952896 [label="feature_extractor.6.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2616756952896 -> 2616757233664
	2616757233664 [label=AccumulateGrad]
	2616757234144 -> 2616757234240
	2616756952816 [label="feature_extractor.6.3.bn2.weight
 (256)" fillcolor=lightblue]
	2616756952816 -> 2616757234144
	2616757234144 [label=AccumulateGrad]
	2616757234288 -> 2616757234240
	2616756952976 [label="feature_extractor.6.3.bn2.bias
 (256)" fillcolor=lightblue]
	2616756952976 -> 2616757234288
	2616757234288 [label=AccumulateGrad]
	2616757234480 -> 2616757235008
	2616756953376 [label="feature_extractor.6.3.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2616756953376 -> 2616757234480
	2616757234480 [label=AccumulateGrad]
	2616757235104 -> 2616757235296
	2616756953456 [label="feature_extractor.6.3.bn3.weight
 (1024)" fillcolor=lightblue]
	2616756953456 -> 2616757235104
	2616757235104 [label=AccumulateGrad]
	2616757235200 -> 2616757235296
	2616756953536 [label="feature_extractor.6.3.bn3.bias
 (1024)" fillcolor=lightblue]
	2616756953536 -> 2616757235200
	2616757235200 [label=AccumulateGrad]
	2616757223488 -> 2616757235488
	2616757235584 -> 2616757235968
	2616756954016 [label="feature_extractor.6.4.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2616756954016 -> 2616757235584
	2616757235584 [label=AccumulateGrad]
	2616757236112 -> 2616757236160
	2616756954096 [label="feature_extractor.6.4.bn1.weight
 (256)" fillcolor=lightblue]
	2616756954096 -> 2616757236112
	2616757236112 [label=AccumulateGrad]
	2616757236544 -> 2616757236160
	2616756954176 [label="feature_extractor.6.4.bn1.bias
 (256)" fillcolor=lightblue]
	2616756954176 -> 2616757236544
	2616757236544 [label=AccumulateGrad]
	2616757236640 -> 2616757236880
	2616756954736 [label="feature_extractor.6.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2616756954736 -> 2616757236640
	2616757236640 [label=AccumulateGrad]
	2616757237024 -> 2616757237168
	2616756954656 [label="feature_extractor.6.4.bn2.weight
 (256)" fillcolor=lightblue]
	2616756954656 -> 2616757237024
	2616757237024 [label=AccumulateGrad]
	2616757237408 -> 2616757237168
	2616756954816 [label="feature_extractor.6.4.bn2.bias
 (256)" fillcolor=lightblue]
	2616756954816 -> 2616757237408
	2616757237408 [label=AccumulateGrad]
	2616757237600 -> 2616757237840
	2616756955296 [label="feature_extractor.6.4.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2616756955296 -> 2616757237600
	2616757237600 [label=AccumulateGrad]
	2616757237888 -> 2616757238080
	2616756955376 [label="feature_extractor.6.4.bn3.weight
 (1024)" fillcolor=lightblue]
	2616756955376 -> 2616757237888
	2616757237888 [label=AccumulateGrad]
	2616757238032 -> 2616757238080
	2616756955456 [label="feature_extractor.6.4.bn3.bias
 (1024)" fillcolor=lightblue]
	2616756955456 -> 2616757238032
	2616757238032 [label=AccumulateGrad]
	2616757238224 -> 2616757238272
	2616757238560 -> 2616757238896
	2616756955856 [label="feature_extractor.6.5.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2616756955856 -> 2616757238560
	2616757238560 [label=AccumulateGrad]
	2616757238944 -> 2616757239088
	2616756955936 [label="feature_extractor.6.5.bn1.weight
 (256)" fillcolor=lightblue]
	2616756955936 -> 2616757238944
	2616757238944 [label=AccumulateGrad]
	2616757239328 -> 2616757239088
	2616756956016 [label="feature_extractor.6.5.bn1.bias
 (256)" fillcolor=lightblue]
	2616756956016 -> 2616757239328
	2616757239328 [label=AccumulateGrad]
	2616757239568 -> 2616757228480
	2616756956576 [label="feature_extractor.6.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2616756956576 -> 2616757239568
	2616757239568 [label=AccumulateGrad]
	2616757229056 -> 2616757234624
	2616756956496 [label="feature_extractor.6.5.bn2.weight
 (256)" fillcolor=lightblue]
	2616756956496 -> 2616757229056
	2616757229056 [label=AccumulateGrad]
	2616757236352 -> 2616757234624
	2616756956656 [label="feature_extractor.6.5.bn2.bias
 (256)" fillcolor=lightblue]
	2616756956656 -> 2616757236352
	2616757236352 [label=AccumulateGrad]
	2616757234096 -> 2616757230880
	2616756957136 [label="feature_extractor.6.5.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2616756957136 -> 2616757234096
	2616757234096 [label=AccumulateGrad]
	2616757239136 -> 2616757239376
	2616756957216 [label="feature_extractor.6.5.bn3.weight
 (1024)" fillcolor=lightblue]
	2616756957216 -> 2616757239136
	2616757239136 [label=AccumulateGrad]
	2616757229968 -> 2616757239376
	2616756957296 [label="feature_extractor.6.5.bn3.bias
 (1024)" fillcolor=lightblue]
	2616756957296 -> 2616757229968
	2616757229968 [label=AccumulateGrad]
	2616757239664 -> 2616757229488
	2616757227184 -> 2616645133760
	2616756958496 [label="feature_extractor.7.0.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	2616756958496 -> 2616757227184
	2616757227184 [label=AccumulateGrad]
	2616757227472 -> 2616645684336
	2616756958576 [label="feature_extractor.7.0.bn1.weight
 (512)" fillcolor=lightblue]
	2616756958576 -> 2616757227472
	2616757227472 [label=AccumulateGrad]
	2616757233040 -> 2616645684336
	2616756958656 [label="feature_extractor.7.0.bn1.bias
 (512)" fillcolor=lightblue]
	2616756958656 -> 2616757233040
	2616757233040 [label=AccumulateGrad]
	2616645339408 -> 2616645341376
	2616756959216 [label="feature_extractor.7.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2616756959216 -> 2616645339408
	2616645339408 [label=AccumulateGrad]
	2616645346704 -> 2616645346992
	2616756959136 [label="feature_extractor.7.0.bn2.weight
 (512)" fillcolor=lightblue]
	2616756959136 -> 2616645346704
	2616645346704 [label=AccumulateGrad]
	2616645353280 -> 2616645346992
	2616756959296 [label="feature_extractor.7.0.bn2.bias
 (512)" fillcolor=lightblue]
	2616756959296 -> 2616645353280
	2616645353280 [label=AccumulateGrad]
	2616634305808 -> 2616646390288
	2616756959776 [label="feature_extractor.7.0.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2616756959776 -> 2616634305808
	2616634305808 [label=AccumulateGrad]
	2616646401136 -> 2616633225088
	2616756959856 [label="feature_extractor.7.0.bn3.weight
 (2048)" fillcolor=lightblue]
	2616756959856 -> 2616646401136
	2616646401136 [label=AccumulateGrad]
	2616646174608 -> 2616633225088
	2616756959936 [label="feature_extractor.7.0.bn3.bias
 (2048)" fillcolor=lightblue]
	2616756959936 -> 2616646174608
	2616646174608 [label=AccumulateGrad]
	2616633225184 -> 2616644787392
	2616633225184 [label=CudnnBatchNormBackward0]
	2616646174224 -> 2616633225184
	2616646174224 [label=ConvolutionBackward0]
	2616757232416 -> 2616646174224
	2616645683472 -> 2616646174224
	2616756957776 [label="feature_extractor.7.0.downsample.0.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	2616756957776 -> 2616645683472
	2616645683472 [label=AccumulateGrad]
	2616645337776 -> 2616633225184
	2616756957856 [label="feature_extractor.7.0.downsample.1.weight
 (2048)" fillcolor=lightblue]
	2616756957856 -> 2616645337776
	2616645337776 [label=AccumulateGrad]
	2616645350016 -> 2616633225184
	2616756957936 [label="feature_extractor.7.0.downsample.1.bias
 (2048)" fillcolor=lightblue]
	2616756957936 -> 2616645350016
	2616645350016 [label=AccumulateGrad]
	2616612939776 -> 2616757371088
	2616756960336 [label="feature_extractor.7.1.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	2616756960336 -> 2616612939776
	2616612939776 [label=AccumulateGrad]
	2616757371232 -> 2616757371280
	2616756960416 [label="feature_extractor.7.1.bn1.weight
 (512)" fillcolor=lightblue]
	2616756960416 -> 2616757371232
	2616757371232 [label=AccumulateGrad]
	2616757371424 -> 2616757371280
	2616756960496 [label="feature_extractor.7.1.bn1.bias
 (512)" fillcolor=lightblue]
	2616756960496 -> 2616757371424
	2616757371424 [label=AccumulateGrad]
	2616757371712 -> 2616757372096
	2616756961056 [label="feature_extractor.7.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2616756961056 -> 2616757371712
	2616757371712 [label=AccumulateGrad]
	2616757372192 -> 2616757372288
	2616756960976 [label="feature_extractor.7.1.bn2.weight
 (512)" fillcolor=lightblue]
	2616756960976 -> 2616757372192
	2616757372192 [label=AccumulateGrad]
	2616757372480 -> 2616757372288
	2616756961136 [label="feature_extractor.7.1.bn2.bias
 (512)" fillcolor=lightblue]
	2616756961136 -> 2616757372480
	2616757372480 [label=AccumulateGrad]
	2616757372576 -> 2616757372912
	2616757141904 [label="feature_extractor.7.1.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2616757141904 -> 2616757372576
	2616757372576 [label=AccumulateGrad]
	2616757373056 -> 2616757373344
	2616757141984 [label="feature_extractor.7.1.bn3.weight
 (2048)" fillcolor=lightblue]
	2616757141984 -> 2616757373056
	2616757373056 [label=AccumulateGrad]
	2616757373200 -> 2616757373344
	2616757142064 [label="feature_extractor.7.1.bn3.bias
 (2048)" fillcolor=lightblue]
	2616757142064 -> 2616757373200
	2616757373200 [label=AccumulateGrad]
	2616757373488 -> 2616757373632
	2616757373728 -> 2616757374256
	2616757142544 [label="feature_extractor.7.2.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	2616757142544 -> 2616757373728
	2616757373728 [label=AccumulateGrad]
	2616757374400 -> 2616757374496
	2616757142624 [label="feature_extractor.7.2.bn1.weight
 (512)" fillcolor=lightblue]
	2616757142624 -> 2616757374400
	2616757374400 [label=AccumulateGrad]
	2616757374688 -> 2616757374496
	2616757142704 [label="feature_extractor.7.2.bn1.bias
 (512)" fillcolor=lightblue]
	2616757142704 -> 2616757374688
	2616757374688 [label=AccumulateGrad]
	2616757374880 -> 2616757375120
	2616757143264 [label="feature_extractor.7.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2616757143264 -> 2616757374880
	2616757374880 [label=AccumulateGrad]
	2616757375264 -> 2616757375360
	2616757143184 [label="feature_extractor.7.2.bn2.weight
 (512)" fillcolor=lightblue]
	2616757143184 -> 2616757375264
	2616757375264 [label=AccumulateGrad]
	2616757375504 -> 2616757375360
	2616757143344 [label="feature_extractor.7.2.bn2.bias
 (512)" fillcolor=lightblue]
	2616757143344 -> 2616757375504
	2616757375504 [label=AccumulateGrad]
	2616757375792 -> 2616645893808
	2616757143824 [label="feature_extractor.7.2.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2616757143824 -> 2616757375792
	2616757375792 [label=AccumulateGrad]
	2616757378336 -> 2616757376128
	2616757143904 [label="feature_extractor.7.2.bn3.weight
 (2048)" fillcolor=lightblue]
	2616757143904 -> 2616757378336
	2616757378336 [label=AccumulateGrad]
	2616757376032 -> 2616757376128
	2616757143984 [label="feature_extractor.7.2.bn3.bias
 (2048)" fillcolor=lightblue]
	2616757143984 -> 2616757376032
	2616757376032 [label=AccumulateGrad]
	2616757377856 -> 2616757376176
	2616757383952 -> 2616757379536
	2616757383952 [label=TBackward0]
	2616757378240 -> 2616757383952
	2616757419328 [label="fc1.weight
 (512, 2048)" fillcolor=lightblue]
	2616757419328 -> 2616757378240
	2616757378240 [label=AccumulateGrad]
	2616757372336 -> 2616646059296
	2616757372336 [label=TBackward0]
	2616757376464 -> 2616757372336
	2616757414928 [label="fc2.weight
 (1, 512)" fillcolor=lightblue]
	2616757414928 -> 2616757376464
	2616757376464 [label=AccumulateGrad]
	2616646059296 -> 2616756950016
}
